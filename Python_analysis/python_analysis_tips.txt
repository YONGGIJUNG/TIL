

https://teddylee777.github.io/pandas/10minutes-to-pandas-%EB%B6%80%EB%8F%99%EC%82%B0%EC%8B%A4%EC%A0%9C%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0

https://jsideas.net/daily_to_weekly/

https://blog.naver.com/PostView.nhn?blogId=okkam76&logNo=221372134987&parentCategoryNo=&categoryNo=27&viewDate=&isShowPopularPosts=false&from=postList

https://stackoverrun.com/ko/q/9675748

https://wikidocs.net/46755

https://3months.tistory.com/296

https://sikaleo.tistory.com/40

https://data-make.tistory.com/139


cols = df.columns
cols_fnl = cols.drop(['area','city'])
df2.columns=['area','city','pdate','cnt']



data.corr()
%matplotlib inline   #쥬피터노트북에서 이미지 표시가능하게 하는 쥬피터노트북 매직함수
import matplotlib.pyplot as plt 
import seaborn as sns  
plt.figure(figsize=(15,15))
sns.heatmap(data = data.corr(), annot=True, 
fmt = '.2f', linewidths=.5, cmap='Blues')

df = raw.corr()

sns.clustermap(df, 
               annot = True,      # 실제 값 화면에 나타내기
               cmap = 'RdYlBu_r',  # Red, Yellow, Blue 색상으로 표시
               vmin = -1, vmax = 1, #컬러차트 -1 ~ 1 범위로 표시
              )

			  
# 삼각형
df = raw.corr()
# 그림 사이즈 지정
fig, ax = plt.subplots( figsize=(7,7) )

# 삼각형 마스크를 만든다(위 쪽 삼각형에 True, 아래 삼각형에 False)
mask = np.zeros_like(df, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# 히트맵을 그린다
sns.heatmap(df, 
            cmap = 'RdYlBu_r', 
            annot = True,   # 실제 값을 표시한다
            mask=mask,      # 표시하지 않을 마스크 부분을 지정한다
            linewidths=.5,  # 경계면 실선으로 구분하기
            cbar_kws={"shrink": .5},# 컬러바 크기 절반으로 줄이기
            vmin = -1,vmax = 1   # 컬러바 범위 -1 ~ 1
           )  
plt.show()


data = df.pivot_table(index = 'size', columns = 'day', values = 'tip', aggfunc = 'sum' )
data.head()
sns.heatmap(data)   # 기본 생성


# 값 표시할때

sns.heatmap(data, 
           annot = True, fmt = '.0f')

# 글자 폰드 조정하기(글자 크게 보이기)
sns.heatmap(data, 
            annot = True, fmt = '.0f', 
            annot_kws = {'size' : 20})

# 글자 폰트 작게
sns.heatmap(data, 
            annot = True, fmt = '.0f', 
            annot_kws = {'size' : 7})


fmt1 = '%d x %d = %d'%(a,b,a*b)
print(fmt1)   #  5 x 8 = 40
fmt2 = '{} x {} = {}'.format(a,b,a*b)

			  
fmt4 = f'{a} x {b} = {a*b}'


import seaborn as sns

# 데이터 준비하기 (하고 싶은 데이터프레임으로 변경 가능)
tips = sns.load_dataset("tips")

# plot swarmplot
sns.swarmplot(data=tips, x="day", y="total_bill")
# plot boxplot
sns.boxplot(data=tips, x="day", y="total_bill",  
            showcaps=False,             # 박스 상단 가로라인 보이지 않기
            whiskerprops={'linewidth':0}, # 박스 상단 세로 라인 보이지 않기 
            showfliers=False,           # 박스 범위 벗어난 아웃라이어 표시하지 않기
            boxprops={'facecolor':'None'}, # 박스 색상 지우기
        )			  


https://m.blog.naver.com/PostView.nhn?blogId=kiddwannabe&logNo=221205309816&proxyReferer=https:%2F%2Fwww.google.com%2F


# 마커 추가하기
folium.Marker([37.5536067,126.9674308],    # 서울역위치
              tooltip="서울역(마우스올리면보여짐)",
              popup="서울역(클릭하면 보여짐)",
              ).add_to(m)



from folium.plugins import MiniMap

# 지도 생성하기
m = folium.Map(location=[37.5536067,126.9674308],   # 기준좌표: 서울역
               zoom_start=12)

# 미니맵 추가하기
minimap = MiniMap() 
m.add_child(minimap)

# 마커 추가하기
folium.Marker([37.5536067,126.9674308],    # 서울역위치
              tooltip="서울역(마우스올리면보여짐)",
              popup="서울역(클릭하면 보여짐)",
              ).add_to(m)
m		



from tqdm.notebook import tqdm

for i in tqdm(range(10)):
    print(i)
    time.sleep(0.5)


! pip  install matplotlib=3.0.3
# 버전 지정해서 설치하기
! pip install matplotlib=3.1.2

# 최신 버전으로 업그레이드하기
! pip install matplotlib --upgrade


# 그림 사이즈 지정
fig, ax = plt.subplots( figsize=(10,60) )
# 히트맵 그리기
sns.heatmap(data = data)

# 축 조정
b, t = plt.ylim() # discover the values for bottom and top
b += 0.5 # Add 0.5 to the bottom
t -= 0.5 # Subtract 0.5 from the top
plt.ylim(b, t) # update the ylim(bottom, top) values

plt.show() 



! pip install python-pptx

# 필요한 라이브러리 불러오기
from pptx import Presentation
from pptx.enum.text import PP_ALIGN   # 정렬 설정하기
from pptx.util import Pt      # Pt 폰트사이즈

# pptx 파일 열기
pptx_fpath = './명패포맷.pptx'
prs = Presentation(pptx_fpath)

# 슬라이드 지정하기
slide_num = 0
slide = prs.slides[slide_num]

# 슬라이드 내 shape 사전 만들기
shapes_list = slide.shapes
shape_index = {}
for i, shape in enumerate(shapes_list):
    shape_index[ shape.name ] = i
print(shape_index)   # {'Box_down': 0, 'Box_up': 1, 'name2': 2, 'name1': 3}

def text_on_shape(shape, input_text, font_size = 95, font_color = 'black', bold = True):

    # shape 내 텍스트 프레임 선택하기 & 기존 값 삭제하기
    text_frame = shape.text_frame
    text_frame.clear()

    # 문단 선택하기 
    p = text_frame.paragraphs[0]

    # 정렬 설정: 중간정렬
    p.alighnment = PP_ALIGN.CENTER  

    # 텍스트 입력 / 폰트 설정
    run = p.add_run()   
    run.text = input_text
    font = run.font
    font.size = Pt(font_size)
    font.bold = bold 
    font.name = None

# 하나의 shape 선택하기
shape_name = 'name1'
shape_select = shapes_list[ shape_index[ shape_name ]]    

text_on_shape(shape_select, '홍길동')


save_file = './홍길동.pptx'
prs.save(save_file)





만약 abcdef.py 파일 내에,   함수 f1, f2 가 있다면

아래와 같은 import 문으로 이 함수들을 다시 사용할 수 있어요. 

​

from abcdef import f1  # f1 함수만 사용할때
from abcdef import f1, f2    # f1 함수, f2 함수를 사용할때
from abcdef import *   # abcdef.py 파일내 있는 모든 함수/변수를 불러올때




# 라이브러리 설치
! pip install pytube3

from pytube import YouTube
video_url = 'https://www.youtube.com/watch?v=Zg3j6anDU6U'
yt = YouTube(video_url)

print("[영상 제목]", yt.title)  # 영상제목
print("[영상 게시자]", yt.author) # 영상 게시자
print("[조회수]", yt.views)
print("[평균평점]", yt.rating) # 평균 평점
print("[영상길이(초)]", yt.length)
print("[연령제한여부]", yt.age_restricted)
print("[영상 설명]", yt.description) # 영상 설명
print("[썸네일URL]", yt.thumbnail_url) # 썸네일 url 주소


yt.streams.all()

# 전송 포맷 중 첫번째 선택
stream = yt.streams.all()[0]
stream   # <Stream: itag="18" mime_type="video/mp4" res="360p" fps="30fps" vcodec="avc1.42001E" acodec="mp4a.40.2" progressive="True" type="video">

# 내가 원하는 영상만 선택하기
# 음성만 선택시
yt.streams.filter(only_audio = True).all()
# 내가 원하는 영상만 선택하기
# mp4만
yt.streams.filter(file_extension = 'mp4').all( )


stream = yt.streams.filter(file_extension = 'mp4').all( )[0]
stream   # <Stream: itag="18" mime_type="video/mp4" res="360p" fps="30fps" vcodec="avc1.42001E" acodec="mp4a.40.2" progressive="True" type="video">


# 영상 다운로드
stream.download()

# 파일 이름 지정 
## 폴더지정 가능
stream.download(output_path='test', filename = 'KOBE', filename_prefix= 'R.I.P_')

yt.captions.all()
caption = yt.captions.get_by_language_code('ko')

# 언어로 자막 선택하기
## 한글 자막 1순위로 선택하기. 만약 한글 자막이 없다면 자막 리스트 중 첫 번째 자막 선택하기
caption = yt.captions.get_by_language_code('ko')
if caption == None:
    caption = yt.captions.all()[0]

# 자막 살펴보기(xml 포맷)
caption.xml_captions

# 자막 살펴보기(srt 포맷)
print(caption.generate_srt_captions())

# 자막 다운받기: download("파일명")
caption.download( yt.title )





sns.scatterplot(x = 'total_bill', y = 'tip', data = raw, hue = 'sex')
sns.lineplot(x = 'total_bill', y = 'tip', data = raw, hue = 'sex') 

sns.lmplot(x = 'total_bill', y = 'tip', data = raw, hue = 'sex', col='day')
sns.lmplot(x = 'total_bill', y = 'tip', data = raw, hue = 'sex', col='day', col_wrap= 2)



import pandas as pd
import pandas_profiling

# 레포트 생성 --> html 파일로 저장하기  
## 한글이 깨지시는 분은 제일 아래 코드로 실행해주세요
raw = pd.read_excel('파일명.xlsx')
report = raw.profile_report()
report.to_file('report.html')



import pandas as pd
import pandas_profiling

############ 한글 폰트 지정하는 부분 #################
import matplotlib
from matplotlib import font_manager, rc
import platform

if platform.system() == 'Windows':
# 윈도우인 경우
    font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
    rc('font', family=font_name)
else:    
# Mac 인 경우
    rc('font', family='AppleGothic')
    
matplotlib.rcParams['axes.unicode_minus'] = False   
#그래프에서 마이너스 기호가 표시되도록 하는 설정입니다.


# 레포트 생성 --> html 파일로 저장하기  
## 한글이 깨지시는 분은 제일 아래 코드로 실행해주세요
raw = pd.read_excel('파일명.xlsx')
report = raw.profile_report()
report.to_file('report.html')	
			  
			  
pip install pandas_profiling
			  

pandas profiling

pandas-profiling.github.io

import pandas-profiling as pp

df.profile_report()



# 토픽 정리하기
TOPIC_change = {    '조작성' : '사용성',    '수납/공간':'사용성',    '용량' : '사용성',    '냄새' : '사용성',
    '관리' : '사용성',    '활용도' : '사용성',    '휴대성' : '사용성',    '관리' : '사용성',    '색상' : '디자인',
    '기능' : '성능',    '세척' : '관리',       '제품구성' : '가격'}
raw['topic_modi'] = raw['topic'].apply(lambda x: TOPIC_change[x] if x in TOPIC_change.keys() else x)

topic_pivot = pd.pivot_table(data = raw, index = 'brand', columns = 'topic_modi',values = 'product_id', aggfunc='count',fill_value=0)
topic_sorting = raw.pivot_table(index = 'topic_modi', values = 'score', aggfunc='count').sort_values(by = 'score', ascending = False).index
topic_pivot[topic_sorting]


score_df = pd.pivot_table(data = raw, index = 'brand', columns = 'topic',values = 'score', aggfunc='mean',fill_value=0, )
score_df = score_df[topic_sorting]
score_df.style.format("{:.3}")

import plotly.graph_objects as go

categories = score_df.columns[1:]
fig = go.Figure()

for i in range(len(score_df)):
    fig.add_trace(go.Scatterpolar(
          r=score_df.iloc[i,1:],
          theta=categories,
          fill='toself',
          name=score_df.index[i],
        opacity = 0.7     
    ))
    
fig.update_layout(
  polar=dict(
    radialaxis=dict(
      visible=True,
      range=[4.4, 5]
    )),
  showlegend=True
)



pip install jupyter_contrib_nbextensions      # 라이브러리 설치
jupyter contrib nbextension install --user    # 쥬피터노트북에서 보일 수 있도록 등록



http://localhost:8888/nbextensions  


# 데이터 값 실수. 소수점 두째자리까지 표시
pd.options.display.float_format = '{:.2f}'.format





# real = 실제 값,   prediction = 예측한 값
from sklearn.metrics import confusion_matrix
confusion_matrix(real, prediction)  #confusion matrix 표시


from sklearn.metrics import precision_score, recall_score, f1_score
precision_score(real, prediction)  #precision(정밀도)
recall_score(real, prediction)     #sensitivity(민감도), recall(재현율)
f1_score(real, prediction)         # F1 score(정밀도, 민감도 조화평균)


① 뺨을 때렸는데(P) 모기가 있었다면  TP  (Positive 가 True 다)  ▶ 아싸~! 쾌감!
② 뺨을 때렸는데(P) 모기가 없었다면 ㅠ  FP(Positive 가 False 다) ▶ 아프기만 하고.. ㅠ
③ 뺨을 안때렸는데(N) 모기가 있었따면? ㅠ FN(Negative 가 False) ▶ 간지럽고.. 짜증나고. ㅠ
④ 뺨을 안때렸는데(N) 모기가 없었다면   TN(Negative 가 True)  ▶ 숙면 ㅎ

Precision_score(정밀도)는, 
내가 모기가 있다고 예상하고 손을 휘둘렀을때,  실제로 모기가 있어서 잡은 비율을 말합니다.

Precision_score =     TP / P      =        TP / (FP + TP)

이 비율이 높을 수록,  짜증은 감소하고 환희는 증가하겠죠
원샷~원킬~!!


2. Recall_score(재현율)

두 번째는 Recall_score 혹은 Sensitivity 라고 부르는 방식입니다. 
실제로 모기가 있을때(True), 잘 잡느냐(P) 를 평가하는 방법이죠. 


recall_score = TP  / ( True)  = TP / (FN + TP)

이 지표가 높을 수록 모기에 물릴 확률이 적어지겠죠. 


이렇게 예측모델의 정확도를 측정하는 방법은 하나가 아닙니다. 
모기에 물리지 않게 하는것이 중요한지(recall), 
원샷원킬로  휘두를때 잡을 확률이 높은 것이 중요한지(precision) 는 답이 없습니다. 

분류 예측하는 상품/서비스의 특성에 따라 많이 달라지겠죠. 
※ 정밀도와 재현율 두 가지 지표를 비교하기 쉽게 하나의 지표로 전환하여 사용하기도 합니다. 
 ex) 정밀도와 재현율의 조화평균으로 계산한 F1 이 있습니다

 
 
word_coocs = [
    ('부동산','가격',20),
    ('부동산','아파트',10),
    ('아파트','가격', 9),
    ('아파트','강남', 7),
    ('아파트','분양',5),
    ('부동산','토지',5),
    ('아파트','전세', 3),
    ('부동산','대출', 2),
    ('신혼부부','대출',2),
    ('강남','전세',1)
]

# 그래프 그리기 준비
import networkx as nx
import matplotlib.pyplot as plt
import sys


def sna_graph(word_coocs, NETWORK_MAX):
    
    G = nx.Graph()
    i = 0
    
    # edge 를 생성한다
    for word1, word2, count in word_coocs:
        i +=1
        if i > NETWORK_MAX: break
        
        G.add_edge(word1, word2, weight=count)
    
    # MST 모델을 만든다. 
    T = nx.minimum_spanning_tree(G)
    nodes = nx.nodes(T)
    degrees = nx.degree(T)
    
    # node 사이즈를 정해준다
    node_size = []
    for node in nodes:
        ns = degrees[node]*100
        node_size.append(ns)

    # 폰트 정리
    if sys.platform in ["win32", "win64"]:
        font_name = "malgun gothic"
    elif sys.platform == "darwin":
        font_name = "AppleGothic"
        
    # 분석결과를 화면에 표시한다
    plt.figure(figsize=(16,12))    
    nx.draw_networkx(T,
           pos=nx.fruchterman_reingold_layout(G, k=0.5),
           node_size=node_size,
           node_color="yellow",
           font_family=font_name,
           label_pos=1, #0=head, 0.5=center, 1=tail
            with_labels=True,
            font_size=12 )

    plt.axis("off")
    plt.show()

	






xgboost 소개 : 오늘코드 

전체 보기 : http://bit.ly/inflearn_nlp_tutorial

소스코드 : https://github.com/corazzon/KaggleStr...

# XGBoost 소개, 캐글 우승자 인터뷰 소개, 부스팅 알고리즘을 사용해서 점수를 올려보기

* 2015년 캐글 블로그에 xgboost를 사용하여 17건의 우승 솔루션이 공유됨 : http://blog.kaggle.com/2015/12/03/dat...

* 2016년 논문이 등록 됨 : http://dmlc.cs.washington.edu/data/pd...
*  공식문서 : https://xgboost.readthedocs.io/en/lat...

* 분산형 그래디언트 부스팅 알고리즘
* 부스팅 알고리즘은?
    * 부스팅 알고리즘은 약한 예측모형들을 결합하여 강한 예측모형을 만드는 알고리즘
    * 배깅과 유사하게 초기 샘플데이터로 다수의 분류기를 만들지만 배깅과 다르게 순차적이다.
    * 랜덤포레스트의 배깅과는 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦
    * 결정트리(Decision Tree) 알고리즘의 연장선에 있음
    * 여러 개의 결정트리를 묶어 강력한 모델을 만드는 앙상블 방법
    * 분류와 회귀에 사용할 수 있음
    * 무작위성이 없으며 강력한 사전 가지치기를 사용
    * 참고 이미지 : http://www.birc.co.kr/2017/02/06/%EC%...
    * 배깅과 부스팅의 차이점은 udacity에서 설명한 영상이 가장 도움이 되었음
        * 배깅 : https://www.youtube.com/watch?v=2Mg8Q...
        * 부스팅 : https://www.youtube.com/watch?v=GM3CD...
* 타이타닉 경진대회에 사용 예제가 있음


pandas_fcmp.ipynb참고



### multiprocess

https://docs.python.org/ko/3/library/multiprocessing.html

